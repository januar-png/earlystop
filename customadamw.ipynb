{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6854043,"sourceType":"datasetVersion","datasetId":3939696},{"sourceId":6993747,"sourceType":"datasetVersion","datasetId":4019832},{"sourceId":7109151,"sourceType":"datasetVersion","datasetId":4098798},{"sourceId":7333902,"sourceType":"datasetVersion","datasetId":4257481}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"1/2*((0.8367*0.9111)/(0.83670+.9111))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/januar-png/earlystop.git","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install jcopdl","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-20T12:47:28.626497Z","iopub.execute_input":"2024-06-20T12:47:28.627216Z","iopub.status.idle":"2024-06-20T12:47:47.438447Z","shell.execute_reply.started":"2024-06-20T12:47:28.627180Z","shell.execute_reply":"2024-06-20T12:47:47.437277Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting jcopdl\n  Downloading jcopdl-2.3.1.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from jcopdl) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from jcopdl) (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from jcopdl) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from jcopdl) (1.11.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from jcopdl) (2.2.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from jcopdl) (3.7.5)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from jcopdl) (9.5.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from jcopdl) (1.2.2)\nCollecting pyperclip (from jcopdl)\n  Downloading pyperclip-1.9.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from jcopdl) (4.66.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->jcopdl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->jcopdl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->jcopdl) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->jcopdl) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->jcopdl) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->jcopdl) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->jcopdl) (2.32.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->jcopdl) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->jcopdl) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->jcopdl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->jcopdl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->jcopdl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->jcopdl) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->jcopdl) (1.3.0)\nBuilding wheels for collected packages: jcopdl, pyperclip\n  Building wheel for jcopdl (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jcopdl: filename=jcopdl-2.3.1-py2.py3-none-any.whl size=32805 sha256=2640a38cce7e8039fac4fbd3c7f01a64ff302a3e2f6865dd1e5d6a38ad71da78\n  Stored in directory: /root/.cache/pip/wheels/e3/09/97/1271913ce50297b4cb5cdaf1b9dc54814d9d60437864bea0ce\n  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.9.0-py3-none-any.whl size=11002 sha256=5cfc221cb0f8c3a9a49d8bcfde6cda0f27cebf1ed56311bba36ffa5068aa9ab5\n  Stored in directory: /root/.cache/pip/wheels/cc/ae/36/ee17d1de094fcb61e24106cb329b5103861e819f94bef5e10a\nSuccessfully built jcopdl pyperclip\nInstalling collected packages: pyperclip, jcopdl\nSuccessfully installed jcopdl-2.3.1 pyperclip-1.9.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from earlystop import Earlystop","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:44:25.412683Z","iopub.execute_input":"2024-06-20T12:44:25.413000Z","iopub.status.idle":"2024-06-20T12:44:25.744108Z","shell.execute_reply.started":"2024-06-20T12:44:25.412956Z","shell.execute_reply":"2024-06-20T12:44:25.742705Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mearlystop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Earlystop\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'earlystop'"],"ename":"ModuleNotFoundError","evalue":"No module named 'earlystop'","output_type":"error"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-20T12:47:51.152899Z","iopub.execute_input":"2024-06-20T12:47:51.153580Z","iopub.status.idle":"2024-06-20T12:47:54.293832Z","shell.execute_reply.started":"2024-06-20T12:47:51.153547Z","shell.execute_reply":"2024-06-20T12:47:54.292880Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets,transforms\nfrom torch.utils.data import DataLoader","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-20T12:47:54.295605Z","iopub.execute_input":"2024-06-20T12:47:54.296356Z","iopub.status.idle":"2024-06-20T12:47:55.830041Z","shell.execute_reply.started":"2024-06-20T12:47:54.296321Z","shell.execute_reply":"2024-06-20T12:47:55.828947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nimg_size = 224, 224\n\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(7),\n    transforms.RandomResizedCrop(img_size, scale=(0.8, 1)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor()\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(size=(img_size)),\n    transforms.ToTensor()\n])\n\ntrain_set = datasets.ImageFolder('/kaggle/input/penyakit-padi/train', transform = train_transform)\ntrainloader = DataLoader(train_set, batch_size, shuffle = True)\n\nval_set = datasets.ImageFolder('/kaggle/input/penyakit-padi/val', transform = val_transform)\nvalloader = DataLoader(val_set, batch_size, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:47:55.831991Z","iopub.execute_input":"2024-06-20T12:47:55.833948Z","iopub.status.idle":"2024-06-20T12:47:55.995976Z","shell.execute_reply.started":"2024-06-20T12:47:55.833919Z","shell.execute_reply":"2024-06-20T12:47:55.994640Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"feature, labels = next(iter(trainloader))\nprint(feature.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n1, n2 = max(0, 1 - 0.3), 1 + 0.3\nprint(n1, n2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label2cat = train_set.classes","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:47:58.325962Z","iopub.execute_input":"2024-06-20T12:47:58.326906Z","iopub.status.idle":"2024-06-20T12:47:58.330841Z","shell.execute_reply.started":"2024-06-20T12:47:58.326875Z","shell.execute_reply":"2024-06-20T12:47:58.329900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(7, 7, figsize=(20,20))\nfor img,label, ax in zip(feature,labels, axes.flatten()):\n    ax.imshow(img.permute(1, 2, 0).cpu())\n    ax.set_title(f'{label2cat[label.item()]}')\n    ax.axis('off')\nplt.savefig('preprocessing.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig('preprocessing.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jcopdl.callback import Callback","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:48:02.438308Z","iopub.execute_input":"2024-06-20T12:48:02.438650Z","iopub.status.idle":"2024-06-20T12:48:03.392569Z","shell.execute_reply.started":"2024-06-20T12:48:02.438625Z","shell.execute_reply":"2024-06-20T12:48:03.391814Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:48:04.734372Z","iopub.execute_input":"2024-06-20T12:48:04.734885Z","iopub.status.idle":"2024-06-20T12:48:04.739708Z","shell.execute_reply.started":"2024-06-20T12:48:04.734856Z","shell.execute_reply":"2024-06-20T12:48:04.738810Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n    if mode == \"train\":\n        model.train()\n    elif mode == \"val\":\n        model.eval()\n    cost = correct = 0\n    for feature, target in tqdm(dataloader, desc=mode.title()):\n        feature, target = feature.to(device), target.to(device)\n        output = model(feature)\n        loss = criterion(output, target)\n        \n        if mode == \"train\":\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        cost += loss.item() * feature.shape[0]\n        correct += (output.argmax(1) == target).sum().item()\n    cost = cost / len(dataset)\n    acc = correct / len(dataset)\n    return cost, acc","metadata":{"execution":{"iopub.status.busy":"2024-06-20T12:48:05.138922Z","iopub.execute_input":"2024-06-20T12:48:05.139299Z","iopub.status.idle":"2024-06-20T12:48:05.148796Z","shell.execute_reply.started":"2024-06-20T12:48:05.139270Z","shell.execute_reply":"2024-06-20T12:48:05.147637Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def fit(train_set, trainloader, val_set, valloader, model, criterion, optimizer, device, callback, epochs):\n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n        \n        model.eval()\n        with torch.no_grad():\n            val_loss, val_score = loop_fn(\"val\", val_set, valloader, model, criterion, optimizer, device)\n\n        callback.log(\"train_loss\", train_loss)\n        callback.log(\"train_score\", train_score)\n        callback.log(\"val_loss\", val_loss)\n        callback.log(\"val_score\", val_score)\n\n        if callback.early_stopping(\"minimize\", monitor=\"val_loss\") or epoch >= epochs - 1:\n            callback.add_plot([\"train_loss\", \"val_loss\"], scale=\"semilogy\")\n            callback.add_plot([\"train_score\", \"val_score\"], scale=\"linear\")\n            break","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:03:22.803713Z","iopub.execute_input":"2024-06-20T14:03:22.804574Z","iopub.status.idle":"2024-06-20T14:03:22.811961Z","shell.execute_reply.started":"2024-06-20T14:03:22.804542Z","shell.execute_reply":"2024-06-20T14:03:22.810994Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/januar-png/Model.git","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:36:18.652809Z","iopub.execute_input":"2024-06-20T13:36:18.653422Z","iopub.status.idle":"2024-06-20T13:36:19.640074Z","shell.execute_reply.started":"2024-06-20T13:36:18.653392Z","shell.execute_reply":"2024-06-20T13:36:19.638938Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"fatal: destination path 'Model' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"from Model.CNNpenyakitPadi import CNNpenyakitPadi","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:36:19.642167Z","iopub.execute_input":"2024-06-20T13:36:19.642499Z","iopub.status.idle":"2024-06-20T13:36:19.647097Z","shell.execute_reply.started":"2024-06-20T13:36:19.642471Z","shell.execute_reply":"2024-06-20T13:36:19.646222Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNNpenyakitPadi(output_size = len(train_set.classes)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=2e-6)\ncallback = Callback(model, optimizer,early_stop_patience=2)\nepoch = 100","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-20T14:03:29.544888Z","iopub.execute_input":"2024-06-20T14:03:29.545249Z","iopub.status.idle":"2024-06-20T14:03:29.583950Z","shell.execute_reply.started":"2024-06-20T14:03:29.545222Z","shell.execute_reply":"2024-06-20T14:03:29.582972Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"fit(train_set, trainloader, val_set, valloader, model, criterion, optimizer, device, callback, epoch)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:03:29.938987Z","iopub.execute_input":"2024-06-20T14:03:29.939337Z","iopub.status.idle":"2024-06-20T16:16:49.789239Z","shell.execute_reply.started":"2024-06-20T14:03:29.939312Z","shell.execute_reply":"2024-06-20T16:16:49.788278Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Train: 100%|██████████| 20/20 [01:27<00:00,  4.36s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_loss</th>\n      <th>train_score</th>\n      <th>val_loss</th>\n      <th>val_score</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>66</th>\n      <td>0.865082</td>\n      <td>0.896825</td>\n      <td>0.863659</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.863499</td>\n      <td>0.898413</td>\n      <td>0.861953</td>\n      <td>0.902778</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.860844</td>\n      <td>0.901587</td>\n      <td>0.861631</td>\n      <td>0.905556</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.863501</td>\n      <td>0.896032</td>\n      <td>0.863803</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.862248</td>\n      <td>0.901587</td>\n      <td>0.861126</td>\n      <td>0.902778</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.856706</td>\n      <td>0.908730</td>\n      <td>0.860314</td>\n      <td>0.902778</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>0.858617</td>\n      <td>0.898413</td>\n      <td>0.858748</td>\n      <td>0.902778</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0.857189</td>\n      <td>0.908730</td>\n      <td>0.857106</td>\n      <td>0.902778</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.851360</td>\n      <td>0.909524</td>\n      <td>0.859086</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.856662</td>\n      <td>0.907937</td>\n      <td>0.857187</td>\n      <td>0.897222</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"Train: 100%|██████████| 20/20 [01:31<00:00,  4.58s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]\nTrain: 100%|██████████| 20/20 [01:31<00:00,  4.55s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.37s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.88s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.45s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]\nTrain: 100%|██████████| 20/20 [01:26<00:00,  4.31s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.87s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.46s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.44s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.88s/it]\nTrain: 100%|██████████| 20/20 [01:23<00:00,  4.19s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.98s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.53s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:32<00:00,  4.62s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:32<00:00,  4.65s/it]\nVal: 100%|██████████| 6/6 [00:18<00:00,  3.00s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.48s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  3.00s/it]\nTrain: 100%|██████████| 20/20 [01:31<00:00,  4.58s/it]\nVal: 100%|██████████| 6/6 [00:18<00:00,  3.01s/it]\nTrain: 100%|██████████| 20/20 [01:31<00:00,  4.56s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:31<00:00,  4.57s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.45s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.55s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.50s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.52s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.50s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:26<00:00,  4.34s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.91s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.98s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.50s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.39s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.42s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.47s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:26<00:00,  4.32s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.88s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.50s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.55s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.36s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.36s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.45s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.45s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:25<00:00,  4.30s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\nTrain: 100%|██████████| 20/20 [01:26<00:00,  4.34s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.37s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.40s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.91s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.46s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.49s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.39s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.44s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:25<00:00,  4.29s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.84s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.46s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:23<00:00,  4.20s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.87s/it]\nTrain: 100%|██████████| 20/20 [01:27<00:00,  4.38s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\nTrain: 100%|██████████| 20/20 [01:29<00:00,  4.47s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:25<00:00,  4.27s/it]\nVal: 100%|██████████| 6/6 [00:16<00:00,  2.79s/it]\nTrain: 100%|██████████| 20/20 [01:32<00:00,  4.60s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.43s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.92s/it]\nTrain: 100%|██████████| 20/20 [01:31<00:00,  4.55s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.93s/it]\nTrain: 100%|██████████| 20/20 [01:30<00:00,  4.54s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.99s/it]\nTrain: 100%|██████████| 20/20 [01:28<00:00,  4.41s/it]\nVal: 100%|██████████| 6/6 [00:17<00:00,  2.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31m==> Execute Early Stopping at epoch: 75 | Best val_loss: 0.8571\u001b[0m\n\u001b[31m==> Best model is saved at output\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"45*4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize(size=(224,224)),\n    transforms.ToTensor()\n])\ntest_set = datasets.ImageFolder('/kaggle/input/penyakit-padi/test', transform=test_transform)\ntestloader = DataLoader(test_set, shuffle=False, batch_size=180)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature, target = next(iter(testloader))\nfeature, target = feature.to(device), target.to(device)\nprint(feature.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model.load_state_dict(torch.load('/kaggle/working/model/best_model.pth'))\n    model.eval()\n    output = model(feature)\n    preds = output.argmax(1)\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label2cat = train_set.classes\n\nfig, axes = plt.subplots(15,12, figsize=(40,40))\nfor img, label, pred, ax in zip(feature, target, preds, axes.flatten()):\n    ax.imshow(img.permute(1, 2, 0).cpu())\n    font = {\"color\":'r'} if label.item() != pred.item() else {\"color\": 'g'}\n    label, pred = label2cat[label.item()], label2cat[pred.item()]  \n    ax.set_title(f\"label: {label} | pred: {pred}\", fontdict=font)\n    ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"180/15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNNpenyakitPadi(output_size = len(train_set.classes)).to(device)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, testloader, criterion, device):\n    model.load_state_dict(torch.load('/kaggle/working/model/best_model.pth'))\n    model.eval()\n    total_loss = 0.0\n    all_labels = []\n    all_predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predictions = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predictions.cpu().numpy())\n\n    average_loss = total_loss / len(testloader)\n    accuracy = sum(np.array(all_labels) == np.array(all_predictions)) / len(all_labels)\n    \n    class_counts_labels = np.bincount(all_labels)\n    class_counts_predictions = np.bincount(all_predictions)\n\n    print(f'Test Loss: {average_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_predictions))\n\n    print(\"Confusion Matrix:\")\n    cm = confusion_matrix(all_labels, all_predictions)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=test_set.classes, yticklabels=test_set.classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n    \n    if not os.path.exists('confusion_matrix'):\n        os.makedirs('confusion_matrix')\n\n    plt.savefig(f'confusion_matrix/{model.__class__.__name__}.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, testloader, criterion, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nmodel = CNNpenyakitPadi(output_size = 6).to(device)\nsummary(model, (3, 224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\noutput_size = 4  \nmodel = CNNpenyakitPadi(output_size)\n\ndef visualize_feature_maps(model, layer_idx, input_image):\n    activations = model.feature[layer_idx].block(input_image)\n    activations = activations.detach()\n\n    fig, axs = plt.subplots(activations.size(1))\n    fig.suptitle('Feature Map Visualization (Layer {})'.format(layer_idx))\n\n    for i, ax in enumerate(axs):\n        ax.imshow(activations[0, i, :, :].cpu(), cmap='gray')  \n        ax.axis('off')\n        print(f\"feature map: {activations}\")\n\n    plt.show()\n\ndef visualize_relu(model, layer_idx, input_image):\n    activations = model.feature[layer_idx].block(input_image)\n    relu_activations = F.relu(activations)\n    relu_activations = relu_activations.detach()\n\n    fig, axs = plt.subplots(relu_activations.size(1))\n    fig.suptitle('ReLU Visualization (Layer {})'.format(layer_idx))\n\n    for i, ax in enumerate(axs):\n        ax.imshow(relu_activations[0, i, :, :].cpu(), cmap='gray')  \n        ax.axis('off')\n        print(f\"ReLU activation: {relu_activations}\")\n\n    plt.show()\n\ndef visualize_bias(model, layer_idx):\n    layer = model.feature[layer_idx].block.conv2d  # Assuming bias is in Conv2d layer\n    bias = layer.bias.data\n\n    fig, ax = plt.subplots()\n    fig.suptitle('Bias Visualization (Layer {})'.format(layer_idx))\n\n    ax.plot(bias.cpu().numpy())\n    ax.set_xlabel('Filter Index')\n    ax.set_ylabel('Bias Value')\n    print(f\"bias: {bias}\")\n    plt.show()\n\ndef visualize_input_channels(input_image):\n    channels = input_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n\n    fig, axs = plt.subplots(channels.shape[2])\n    fig.suptitle('Input Image Channels Visualization')\n\n    for i, ax in enumerate(axs):\n        ax.imshow(channels[:, :, i], cmap='gray')  \n        ax.axis('off')\n        print(f\"channel {i + 1}: {channels[:, :, i]}\")\n\n    plt.show()\n\nimage_path = '/kaggle/input/rice-desease/datapadi/test/brown_spot/brown_val (50).jpg' \ninput_image = Image.open(image_path)\ntransform = transforms.Compose([\n    transforms.Resize((6, 6)),  \n    transforms.ToTensor()\n])\ninput_image = transform(input_image).unsqueeze(0)\n\nvisualize_input_channels(input_image)\n\nvisualize_feature_maps(model, 0, input_image)\n\nvisualize_relu(model, 0, input_image)\n\nvisualize_bias(model, 0)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nmodel = CNNpenyakitPadi(output_size = len(train_set.classes)).to(device)\nmodel.load_state_dict(torch.load('/kaggle/working/model/best_model.pth'))\nmodel.eval()\n\nactivation1 = {}\njumlah = 100\n\ndef get_activation(name):\n    def hook(module, input, output):\n        activation1[name] = output.detach()\n    return hook\n\nfor name, layer in model.named_modules():\n    if isinstance(layer, (nn.Conv2d, nn.ReLU)):\n        layer.register_forward_hook(get_activation(name))\n\nimg = Image.open('/kaggle/input/padi-data/test/bercak/IMG000000000013.jpg')\nrgb_image = img.convert('RGB')\ntransform = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.ToTensor()\n])\nimg_tensor = transform(rgb_image)\nimg_tensor = img_tensor.unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    output = model(img_tensor)\n    \nfor name in activation1:\n    folder_path = os.path.join('custom_12', name)\n    file = name\n\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    if file in activation1:\n        num_images = min(max(3, activation1[file].shape[1]), 10)\n        for i in range(num_images):\n            current_image = activation1[file][0, i].cpu().numpy()\n            print(f\"Shape of {file}-{i}: {current_image.shape}\")\n            \n            fig, ax = plt.subplots(1, 1)\n            ax.imshow(current_image)\n            ax.axis('off')\n            plt.tight_layout()\n\n            fig.savefig(f'{folder_path}/{file}-{i}.png', dpi=300, transparent=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize(size=(224,224)),\n    transforms.ToTensor()\n])\ntest_set = datasets.ImageFolder('/kaggle/input/penyakit-padi/test', transform=test_transform)\ntestloader = DataLoader(test_set, shuffle=False, batch_size=180)\n\nfeature, target = next(iter(testloader))\nfeature, target = feature.to(device), target.to(device)\nprint(feature.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = test_set.classes\nfor index, class_name in enumerate(class_names):\n    print(f\"name {class_name} label = {index}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data_index, (sample, label) in enumerate(test_set):\n    class_name = test_set.classes[label]\n    print(f\"Index: {data_index}, Class Name: {class_name}, Label: {label}\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.86695 +0.032092+ 0.051306+ 0.049649","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith torch.no_grad():\n    model = CNNpenyakitPadi(output_size = len(train_set.classes)).to(device)\n    model.load_state_dict(torch.load('/kaggle/working/model/best_model.pth'))\n    model.eval()\n    output = model(feature)\n    preds = output.argmax(1)\nprint(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(2,10,2)\ny = x**2\npr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2)\naxes[0].plot(x,y)\naxes[1].plot(y,x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}